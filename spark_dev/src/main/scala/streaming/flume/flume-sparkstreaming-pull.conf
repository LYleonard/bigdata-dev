## define agent
a2.sources = r2
a2.channels = c2
a2.sinks = k2

## define sources
a2.sources.r2.type = exec
a2.sources.r2.command = tail -f /home/hadoop/spark-flume/access.log
a2.sources.r2.shell = /bin/bash -c

## define channels
a2.channels.c2.type = memory
a2.channels.c2.capacity = 1000
a2.channels.c2.transactionCapacity = 100

## define sink
a2.sinks.k2.type = org.apache.spark.streaming.flume.sink.SparkSink
a2.sinks.k2.hostname = master
a2.sinks.k2.port = 9999

# bind the source and sink to the channel
a2.sources.r2.channels = c2
a2.sinks.k2.channel = c2